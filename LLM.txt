LLM

Large Language Model
is a type of llm 
data sy train kiya 
ai understand generate and ineract using human language.
input dngy output dyga phly jo b train nhi tha phly
LLM jab aya prompt likhty wo answer data

prompt mtlb ak word hai llm ma promt khty ham question
llm bhut sary data sy train hota hmany data machine ko diya jo pochy wo answer dyga
chatgpt 
gemini  

LLM se pehle chatbots ‚Äúrules follow‚Äù karte thay,

LangChain = Train track üöÜ (straight path)
LangGraph = Google Maps üó∫Ô∏è (many routes, decisions, loops)

prompt instructions ety llm ko wo text generate krky deta answer

llm
gpt
claud ai 

market ma hai use kr skty Hai ap

every llm apny tariqy sy banaya gya hai
kisi ki speed zayda accuracy multilingual abililites

cloud bangle ma bat nhi kr ksta gemeni kr ksta hai
bhut sary model text ma bat krty image wgaira ma nhi

cloud ma code likha skty usko train hi aisy kiya gya hai
accuracy ma bar kry claude ki zyada hai

twitter ny grok launch kiya hai

llms
real world use case
cahatbots:like bots 
summarizers;NEW PPS PDF
Trasnlation:cinvert English Urdu 
automation:ai code reviews

llms use kr skty hai 
llm kam kasy krta   hai

jo text diya ya output nikalny  phly kya krta process wo
tokenization:
embedding
transformer
prediction

tockenization:jo b text likha hai usko tokenization krty 
parts ma divide krty hai ham usko tokens khty hai
input=most famous cheese in France
toekns[most,famous,cheese,in,france]
array ma convert krty ak space b matter krta hai model meaning nhi nikal skta hai

embedding
token ko vector ma convert krty hai ham
chhese ak world hai array of vector ma distribute krty hai

i love ai model s

[0.01,] har token ma vectore deta hai jo number hai 
jo llm model ko smjhny ma eska mtlb kya hai usko words smjh nhi aye ga

USKO embedding khty hai
har model ka apna hisa hota kasy token bnata hai

vector apple hai
har model apna dyga kasy wo train hai
embedding wagira


Transformer
pora sentence dekhta konsa word important hai kis pr focus hona chaye

what is important
what words are related
what to focus on

the model learns that cheese frnace hai wo focus kry ga konsa important hai word

wo human ki tar kry ga hmm
output b token ki format ma deta hai
jeski zayda probability hai wo pick kry ga 
har model apny hisab y krta hai
usny socha kis pr focus krna model output generate kry ga human answer ma


es satge pr work krta hai
input leta token k formate ma output b data token ki form ma
probability ki base pr answer deta hai 

input text
tokens
embedding
transformer blocks
output embedding 
tokens output tokens

prediction model kasy krta

deep learning is very 
bhut sara output diya multiple words 
har wo probability deta hai jeska zayda hota wo dy deta hai
token sy text ma convert krty ham
multipe token generate krta wo probabailty wala deta zayda 


prediction depends on
traingin dtaa 
the prompt 
temperature
max token length


the dog sat on 
text sy inputm ma convert kiya hamny
phr ya llm ma gya ya dimag lagta jitna train hai
the mat pad enki probabailty zayda hai
ab scond highest probabitly return krty hai

zarori nhi jeska output zayda o output dena hamny

sampliing strategies kya ai
ak outpu kasa dena wo change kr skty probability konsa chaye

apna soch k mutabik output dena hai 

the boy wnet to the
usmny multiple results diya ham chaty hai low probability kam wala dn  hmy

ham prameter change krty kis pr wo sai deta hai output alg alg simplify startegies krty ai


1.Temprature
agr temparture kam hai
tu jo b ouptu token hota hai uska probailtiy hota wo zyda hota

ak ka 60 percentage
40 
10 
1
apko pick krna 60 wala kry ga ham
apko milta
80
79
81
75
85 ab choose krna muskhil sai lg rha confusing answer dyga
yha temparture ata
kam rkha tu 2nd wala output milta

lower 0.2 rkhty acha milta result
1.0 confuse kry ga

jasy tmepature bhrty aye ga wo similar mily ga dekh nhi ksy khy ga konsa pick kry ga
tempareyre am simpliy sai milgy ga


2.top-k-sampling 
jo output mil rha sabsy acha ala pick krna hai
agr koi khrab nhi aye ga choose krna easy rhy ga
 
top wose sorted hota set k=2
top 2 elelment dyga ya nichy wala discard krdu 




Top p Sampling
picks smamleste set token jeski
aisa set token la kr dn jeska probability 0.9 sy zauda hn

ham khy ga starting k 3 la dn
jo token krna jeska top 3 sy zayda hoga

top p wo chaye 

sampliy


3.Min-p

minimum 
jp b min-p ka value hoga 0.1 hai es sy kam wo hata dn Esko

top k fixed output chaye topki 
top p k agr cummulaitce sum hamy set of token la kr dn jeska sum top sy zayda hn
top min kya khta hai wo discard krdu jeski probability kam hai  ham output sample nikal skty hai llm k zariya

kasy kam krta token kasy krty ouptu sample kasy krty ham

Frequency Penalty
LLM jab jawab likhta hai aur same word / phrase bar-bar repeat karne lagta hai,
to frequency_penalty us repetition ko punish karta hai.





Hugging Face Basics + Open-Source LLMs

chatgpt hai wo paid hai ak point k bad paisy dn use kro response nhi sai mily ga
ap jo data likha many personal chezy di apni mera ya data chpt k server pr jarha hai

open source llm
jo open source hai paisy diya bagir llm

ak llm trian krny k liya medical k liya open source hota ham apna contribution dy skty hai

gemma ak model hai google deta hai 
gemini paid hojata gemma free hai open source hai 
jes gemeini sy trian kiya gemma b us sy 

huging face aisa platform ml models datasets ko tools ko host kr ksty hai taky dosry develoers use kr ksy

Hugging Face ek open-source AI platform hai jo pre-trained models, datasets aur tools provide karta hai jisse hum NLP aur LLM applications build, train aur deploy kar sakte hain.


esmy models dataset models infrenceapi b mily gi
ai jo train hota bana hova usko use krna inference khty hai 

datasets difference dta milta jesko use krky train kr skty hai
GitHub pr code rkhty hugginface ma ai model rkhty apna 
hamny web application banye usko directy use kr skty hai wha sy
jo banye hai gamama llma use kr skty bina apna cpu use krky


har model mathematician calculation solve krny k liya dimage chaye hardware cpu gpu

gpt hosted hai apny openai pr hi usky server hota hai
open source hai Esko use krky krty apny system ma

hugging face api dety jesko use krky model use krty hamra cpu chota 

model choose kiya hugging face Esko hose krta apny server pr
apko api dy diya ham jo b input bhjy hugging face khud handle kry ga


ai ko use krny k liya hmy gpu ki zarorat hoti hai
gpu jo hai wo multiple clauclation krny k liya bana hai parallel
cpu ko trian kiya kuch kuch task liya os app run krny k liya
cpu ak bar ma ak task kry ga ak math problem ak time ma

gpu graphical processing unit
graphic ko jaldi render kr ksy phly
1000 math problem ak sath use kr ksta parallel cpu ak hi
cpu ko kho 1000 kro solve time lyga cpu 1000s lyga
gpu ko 1 second ly ga 1000 problems k liya 

ai model ka kam next word predict krna ai bhut sara mathemitcal krta 
calculation ki zarorat hoti hai 1000 clacualtion krni hoti ak word k liya gpu use hota esky liya 

cpu 4 score
cpu 4 core mltb 4 task paralle ma kr skta esky bad krna ya khtm hoga phr hoga 

gpu ma hundered or hazar prlbme ak sath solve kr skta

nvidia rtx 4090 16384 ak time ma

ai ko run krny k liay gpu use krty hai

kya model ko cpu ma run kr ksty hai kr skty slow hoaga wo 

zayda model ly hang krny lg jaye distilbert tinyllma etc small model mtlb

hugging face ak website model mily ga hamy account banye ga 
models datasets mily ga 

models konsy dekh skty 

gemma-3-4b-it ya model image lyga jo b hai usko dekhy answer lakr dyga jo ham query dyga


model paramteters ka mtlb
ai model ma paramters is a number hai jo model learn krta sekhta during traing 
jab model train krty datsets hai jab wo model train krty hai jo wo sekhta hai usko number ma store krta hai usko parameter jeska zayda parmater hai wo zayda sekha hai

4b hai itni learning hai 27 billion laearning ki hai

ai model ka kam next word predict kry kisi model ko hindi sy translation enlgish ma billon rules weights skhta hai 
wo number ma store krta hai

gpt-2 ka 124million parameter hai 
gpt-3 k pas 175billion 

jab model train krta wo different chezy sy skehta hai ak hota
weight
value 
rule 

weight ma 2 word great ko value 0.95 diya 
value jo actual store kry ga
rule ai ma if else nhi hoti
mtlb ak car k extrat kasy krna speed dani kam krna ya khud krta hai llm ya past training pr depend krta hai 
ai har word ko value deta witgh deta kab kitna dena lana hai wo training ma depend krta hai ya paramters khty hai

jo sara data sekha wo numbers ki form ma store krta input deta calculation krta phr output deta kitna zayda hoga utna train hai

agr llm ko cpu ma krna computation wo ram ma krta 
cpu jb b calculation krta ram sy data leta hai

model 15 gb ka hai pora model run kry ga 
3gb ka 7 gb ka hai ram ma load kry ga run kry ga ham

model size kis pr depend krta ya number 
float32 int8 int4 ma 

float 32 4 byte ka leta
int 8 ak byte int 4 0.5 byte

model ka size parmater ma depend krta hai
jes intger ma store usko multipley kro 

agr gpt 2 14m hai float32 ma hai 124*4 kry ga 496mb hai


formula
size*parmatersize

quantization
 jo model ka parmter hai usko high percison sy low precision ma kr dety hai small or fast hoajye ga



Low-size-model
yhi hai model k actual model use na krky quantatize version use krty hai ham 

Naming conversion of models
name ajeeb hai muskil hai 


ham llma othaty hai cloud othaye ga organization hai opensource hai ap apny hisab sy customize krly

first name + model architctire +parmater size+ version + quantized models
thebloke+mistral+7b+instrcut-vo-1+GGUF

google-gemma-7b
ya text generation k liya sai hai



Transfomers Library
har ak liya paossible nhi wo model download kry run kry apny system ma

ak library hai python ki transformer
ap kisi b model ko thorw a pyhton load kr ksty run kr kstyy

google coolab kry ga use ham


from transformers import pipeline

generator = pipeline("text-generation", model="gpt2")

output = generator(
    "Pakistan ka AI future",
    max_length=50,
    num_return_sequences=1
)

print(output[0]["generated_text"])


max length 50 token sy deal kry ga input token or output ka token 50 hoga
varencies ktiny hai 1 kiya
pip k zariya install kiya usko usekntk liya pipeline banya 
generortor ana r diya or parameter diya kuch




Run LLMs Locally with Ollama & LM Studio 




Ollama
ya ak cli hai terminal hai
terminal ma llm ko run kry ga ham

ak enviroment deta Jha llm file dyga ya run kry ga 

wsl install krna hai
ak envoiemnt eta linux ko chla skty hai apny system ma ham

phi ak open source hai micrsoft dia hai

Ollama kyun use karte hain?

Local AI chalane ke liye (internet ke baghair bhi)
LLM (LLaMA, Mistral, etc.) apne PC par

Fast & private
API jaisa use (chat, apps)

Matlab:
ChatGPT jaisa AI, lekin apne laptop par

ollama run tinyollama ya run kry ga ollama ka chota version ka size chota hai original ka zayda hai

yha quontize hi model run kr ksty hai ham apny system ma
ya llm mery local system ma chal rh amera locally memeory wagira use kr ha

PS C:\Users\Saqib> ollama list
NAME                ID              SIZE      MODIFIED
tinyllama:latest    2644915ede35    637 MB    5 minutes ago
PS C:\Users\Saqib>


by defult ak pi deta run krta port pr 11434 ma 

localhost//11434/api/generator

aagr koi offline model run krna
.gguf milna chaye hai




ollama run mistral 
ya doenload krna start krdy ga ya

express server run kry ollama ak api deta hai eska use krky kr ksty pora chatbot bana skty hai ak frinted bana dena ap chatbot sy bat kr ksty api k zariya


apny locahost ma kiya express sy server sy banaya donu ko commence kr krty hai


commands

ollama pull model
ollama run model
ollama list
ollama rm model 



ollma dedicating hai local ma run krny k liya
personal projects k liya ollama
ollama local chlta
hugging global libarray mmilty 
ollama local k liya Jha sy quantatize model mil jaty hai




Lm Studio
ya desktop app hai run la language models k liya
yha b model daly ga question pochy ga answer dyga ya hmy



RAG = Retrieval Augmented Generation

Iska seedha matlab:

Pehle apne data se relevant information nikaalna (Retrieval)
phir us information ki madad se jawab banana (Generation)



Prompt Engineering

hamara prompt jitna sai hoga utna sai hoga answr
act like a trave guide kon hn exmalin 3 places top 3 n Pakistan

prompt structure

who the ai is
instrcutions
response kasa chaye 

types of prompting

roleplay prompting
act-like a startup co-founder and explain ai to a 12-year old

chain of thought prompting
hamny kha llm ko loud thing kro 
har step by step chez hn 

few shiort prompting

phly expel dy input otput dykr 
phr wo estara sy response sy lakr dyga








LangChain

langchain  framework hai llm powered applications bnaty hai ham

react ak framework hai esky bina b ham fronted bana skty thy react k zariya easy hogya fronted sy bana skty

llm bulitn in features deta hai
LangChain ek framework hai jo LLMs (ChatGPT, Ollama, etc.) ko:

tools
memory
databases
APIs
ke sath connect karta hai.
key features

llm:brain hai ya
prompt:llm sy kya krwana chaty hai ap

output parser: llm apko desired ma output lakar dyga jes my ap khy ga

jab b gpt sy pochty hai ak word hota context hai
aj yak day 1 sy pocha 
agr day 1 sy 5 tk aye usko yad nhi rhta usko chat ma ya yad nhi usko

cntext ko memory khty jo b llm k sath krty usko save krty hai ak dafa bata diya name usko yad rhy memory ma ad krty hai

chain:ya k srequence flow hai Esko prompt diya wo llms kpas jaye ga wo outpu dyga

agr langchain use kry chan bana o ya agnet 

chain ma dimag nhi wo llms k pas jaye ga wo usko process kryga reply dyga
agent khud ka dimag lgaya ga 
mujhe esky answer k liya koi tool use krna kry ga reply dyga


chain
chai banaty 
biolld water 
add tea leaver 
pout into cup
serve 
ya chan process dimag nhi lgana hamny

jo prompt llm k pas jaye decision lyga output dyga ya

koi dimag nhi lgya rule follow kry ga 

qna chatbot bnaty koi question bnaty wo answer drtsa


Agent
khud sochta reply deta
agr flight dekhan current time ka 
indigo ixgo api deta flight k liya

agent search flight api use kry ga sab sy chepest dekhy ga flight


ya langchian
chain
agent deta hai

langchain bhut kuch deta

nodejs+gemien sy bnye ga ham

langchain k framework hai jo isa frmaweok jo functionality deta 
tools deta ak chain hai or ak agent hai

chatbot banan ai text summarizer langchain anana

text summarize bhut bara diya wo chota krdy ga

Jha ai ko decide krna pry search krna tool krna real time update esky liy agent use kry ga ham


agr nodejs gpt api use krky chain bana skty ya manually hai

agr tool use kry ya help krty hai prompttempalte function hai outputpraser outpu lakr dyga achy sy


agent k liya langchain haye builtin tool k liya chyae ya 

basic prompt k liya bina langchain
logic flow multiple prompts without langcahin
tools memory decision making k liya lanchain use kry ga


ak chian dlay ga wo process kry ga outpu dy ga

npm i langchain @langchain/openai dotenv

openai ki api use krna chty dosra package install kry ga ham

langchain
prompt tool
lms sy connect krwata 

langchain openai k tool hai 

openai use krna zarair hai ollama sy b api milta local sy b 

langchain/chat_models/ollama ab local sy connect kry ga

llm chaye kahi sy b hoskta local b gemeini ka mistel ka hoskta hai 


openai k liya apenai key chaye

aistodi.google.com website ma jana
get api key mily ga option
getapi option pr click kry ga ham gemini ka use kry ga jo online hai


chain.js 

env ma key 
GOOGLE_API_KEY=key apna 

import {config} from 'dotenv'
config()

imports
{ChatgOOGLEgENERATEIVEAI} 
{LLMChain} 
{PromptTemplate} esky throw hi llm ko prompt dety hau ham


const model0new ChatGoogleGneeratoveAI({
model:|modelsgemini-2.5-flash|,
maxoutputToekns:2048,ya bhut bara token ka na dy ouptu 
temperature:0.7,
apiKet:process.env.Google_API_Key)}

const prompt=PromptTemplate.formTmeplate(
"Expalin the concept og {topic} to a biggner"}
);


const chain=new LLMChai (ya output lakr dyga
llm:model,
prompt:prompt
)

const res=await chain.run(computing)

langchain prompttmeplae+model+logic ya chain hau prompt use krty promptemeplate 




LCEL
ya tarika hai function likhny ka

langchain expression language

ak chain bana rhy prompt ka wo llm k pas jarha wo outpu dyrha

new tarika kya hai
ham llm pipeline bana dyga ham


lcel_Chian.js

import config
config();
ChatGoogleGenerativeAI 
promptTempalte



const model0new ChatGoogleGneeratoveAI({
model:|modelsgemini-2.5-flash|,
maxoutputToekns:2048,ya bhut bara token ka na dy ouptu 
temperature:0.7,
apiKet:process.env.Google_API_Key)}

const prompt=PromptTemplate.formTmeplate(
"Expalin the concept og {topic} to a biggner"}
);


const chain=prompt.pipe(model) hamny pipe k andr model dy diya

const repsonse=await chain.invoke({
question:"what is the future of ai")}


markdown website hai dekh skty friendy 

prompt .pipe(llm) dydiya chain hogya call kry ga

outputpraser use kry

ak desired formte ma output chaye hamy 
import 

const outputPraser=new StringOuptuPraser();
const choan=prompt.pipe*chain)/pipe(outputPraser)

desired output ma chaye ya

water filter system
sab sy phly prompttemplate kry ga input formate
phly model ko dyga wo output lakr dyga usko ouptu[raser kry ga




import fs from "fs";
import { pipeline } from "@xenova/transformers";
import hnswlib from "hnswlib-node";

const embedder = await pipeline(
  "feature-extraction",
  "Xenova/all-MiniLM-L6-v2"
);

// Load data
const text = fs.readFileSync("data.txt", "utf-8");

// Chunking
const chunks = [];
for (let i = 0; i < text.length; i += 500) {
  chunks.push(text.slice(i, i + 500));
}

// Create index
const dim = 384;
const index = new hnswlib.HierarchicalNSW("cosine", dim);
index.initIndex(chunks.length);

// Embeddings
for (let i = 0; i < chunks.length; i++) {
  const emb = await embedder(chunks[i], {
    pooling: "mean",
    normalize: true,
  });
  index.addPoint(emb.data, i);
}

// Save index
index.writeIndex("index.bin");
fs.writeFileSync("chunks.json", JSON.stringify(chunks));

console.log("‚úÖ Data indexed successfully");import fs from "fs";
import hnswlib from "hnswlib-node";
import { pipeline } from "@xenova/transformers";

const embedder = await pipeline(
  "feature-extraction",
  "Xenova/all-MiniLM-L6-v2"
);

// Load index
const chunks = JSON.parse(fs.readFileSync("chunks.json"));
const index = new hnswlib.HierarchicalNSW("cosine", 384);
index.readIndex("index.bin");

// Local LLM (light model)
const generator = await pipeline(
  "text-generation",
  "Xenova/phi-2"
);

export async function ask(question) {
  // Question embedding
  const qEmb = await embedder(question, {
    pooling: "mean",
    normalize: true,
  });

  // Fetch relevant chunks
  const ids = index.searchKnn(qEmb.data, 2).neighbors;
  const context = ids.map((i) => chunks[i]).join("\n");

  // Strict RAG prompt
  const prompt = `
Answer ONLY from the context below.
If not found, say "Information not available".

Context:
${context}

Question:
${question}

Answer:
`;

  const out = await generator(prompt, { max_new_tokens: 150 });
  return out[0].generated_text;
}


web ma use langchain ka

2Ô∏è‚É£ Apne Data se Q&A (PDF, DB, Docs)
Aap ke paas PDFs / database hota hai
LangChain:

data ko embeddings mein convert karta hai
vector database (FAISS, Pinecone, Chroma) use karta hai
relevant info nikal ke LLM ko deta hai

üëâ Example: ‚ÄúIs document mein refund policy kya hai?‚Äù

3Ô∏è‚É£ Search + AI (RAG system)

User ka question
LangChain pehle search karta hai (docs / DB / web)
Phir LLM se grounded answer generate karta hai
üëâ Isko RAG (Retrieval Augmented Generation) kehte hain


LangChain Agents


chain 
agent

agent sochta hai decide krta phr act krta hai 
chain sedha sedha process jo llm k pas jaye ga output yga lady ga

koi query pochi usmy google search required or  agent use hota hai

hamny lllm sy pocha wo ecide krta koi tool required hai ya nhi
agr wether current wo batany ma galti kiya
data pr train kia 224 tk maximum pata hoga
current time kya horha current weather jana esky pas nhi hoga eska data wo wetsher api call kry ga
agr external time kya hai 

tools dekhta agr zarorat
web search
caluclaotr
document eader
databas query apka jo 
adapter real time databse ko gent sy conntec krta
python code exuextuon


langcahi adapter eta hai jesky zriya ham openai use krty hai

google-genia es adapter k zariya use kr rhy ham
agr weather api chaye agent sy connect krlo wo call kry ga


packages
langchain install krna hoga 
base tools chaye agent bhut use kr ksta hai 
@langchain/ore ya install kry ga
prompt formatted krna
chain connected 
lel chaye

@laginchain/community
ya external service sy connected krny b madad krti hai
current nes chaye ham google sy kry ga
ham third api use kry ga
SerpApi google api use r skty hai
PineCorn Vector b
Huggingface models

enko use krny k liya pacjage chaye wo langchain/community hai


@lagchain/openai
@lagnchain/google-genai 

@langchain/core
jo b package se krna core hona lazmi hai


official documents
langchain ka
top ma api resfernce r jaye mil jaye ga 
custom tool b bana skty hai ham

chat.langinchain.com
yha lanchain sy poch skty hai koi package ni mil rhy 
esmy change hota rhta enka version lanch horha hai 

agr relatime hatbot chaye relatime llm  pas nhi
esky pas required data hai ya tool use kry ga google search 

SerpApi tool
google search api hai
jo b question es sy pochu
ya geographic ki base pr ata result
agr Pakistan diya 

ya kam serpapi use kry ga ham

google search ak search engine hai
Esko jo b relative info lgti wo dydata hai wo kis news channel ka hoskta koi koi or
serpapi json a deta jo googleserach a ta wo

snippets preview hota 
ak url titile ak message es message ko preview khty hai search krny k bad jo ata message 

jasy wheatspp ta mesgae chota preview khty usko

sarpapi register krna hai
usky bad api key pr jana mil jaye gi

JAB npm ak library jah package mlty bhut sry hmy

jab b pakcgae install krty jo exsiiting package k sath shae krta npm 
dotnv k sath comaptibale i rrent 
jab b package isnatll kry 
--legacy-peer-deps 
jo arha issye solve hoaye ga k compatible nhi dotenv k sath lanchain

ya flag sy ya dpeendcy isuuse ignore krd
eta hai


Agent Ai Power News

llm nhi kr ksta tool use kry ga direct nhi kr ksty langchain sath ry ga connect adapter mil gya 

api key dotnv ma

imports
{chatGoogleGneratioveai}
{initialieAgentExcutiveWithOptions
SerpApi 


const model=new ChatGoogleGneerativeAi({
model:"model/gemini-2.50flash",
maxoutput:2048,
temattrue:
apikey:
(}

const agent=await inilizeagentexcutorwithoptions(
[seat=rchapi,wesatehrtool] ya khud agent decide kry ga kya hcyae wo khud use kry ga agr nhi llm sy jwab dyga 
model
}

const res=await agent.invoke({
input:'waht is the latest news about isro"
)}



Bonus Point

LLM Wrapers opneai
chains
agents
tools 
memory cntext
propmts
outputpraser kya onach chaye json xml
docuemntloader text spillters
vector db
runnables


summary

langchain
chain ->llm chaye bas
agent->llt+tool khud decode kry ga konsa tool chaye




why used langchain
2Ô∏è‚É£ Chat memory rakhne ke liye üí¨

LangChain:

previous messages yaad rakhta hai
long conversation handle karta hai

üëâ Example:
User: ‚Äúmera naam Ali hai‚Äù
Baad mein: ‚Äúmera naam kya hai?‚Äù
‚û°Ô∏è AI correctly answer karega

3Ô∏è‚É£ Apne data se jawab lene ke liye üìÑ

LLM:

sirf general knowledge janta hai
LangChain:
PDFs, DB, Excel, Docs se data read karta hai
relevant info LLM ko deta hai

üëâ Example: company policy bot, student notes Q&A

4Ô∏è‚É£ Search + AI (RAG) ke liye üîç

LangChain:

pehle data/search karta hai
phir usi data se answer banwata hai
Result:
hallucination kam
accurate answers

5Ô∏è‚É£ Tools use karwane ke liye üõ†Ô∏è

LangChain AI ko sikha sakta hai:

calculator
APIs
database queries
web search
AI khud decide karta hai:

‚Äúis sawal ke liye calculator use karna chahiye‚Äù

6Ô∏è‚É£ Production-ready apps ke liye üöÄ

Without LangChain:

sab cheez khud likhni padti
With LangChain:

prompts
chain
agents
memory
retries
sab ready milta hai






MCP Server Explained for Beginners


model context protocol
ak llm or ak external data eksy darmyan ma mcp chaye
ya ak standard vise protocol hai ak tariq hai jesky thorw external data k sath connect kr ksty hai

ak llm kisi data set pr train hai aisa bhut sara data hai jo external hai
jasy services data
jasy personal data jo gpt gemni k pas nhi

ak kya choty storage k liya upload krdu 
agr gbs ma data hai tu ya estara nhi kr ksty
jasy finicail hai march 2025 ka wo gbs ma hai

ag ksii company ka data 15 20 gb ka hai llms k pas es ka conection hn wo msp k zariya krty hai


mcp tool box hai multipe hoskty hai
ya protol hai jesky thorw externdata ko llm k sath connect krty hai 


bina mcp k kry skty thy
llm sy external db sy connect krna wo excel sheet ma wo sql ma wo mongodb ma hoskta wo audio hoskta 

agr na kry difference compines alg tariq nikaly ga llm sy connect krny sy

excel or krta sql or krta har type of data sy connect k liya connectivity chaye

esny kha ak protocol hona chaye ak data ko external sy connect llm kr ksy hai

har company kry security issue
ak standard protocol hona chaye tha

mcp sy tools bnaty hai ham


where can use mcp
tool hai
weather mcp server
currenct convertor mcp server
database mcp server 


StdioServerTransport
communciton t ry ga mcp server communicate kry ga llm or user k sath

modelconextsevr packagehai 


ham jo b mcp server bnaye ga us ko use krny k liya mcp client chaye
set of tools ko use krny k liya mcp client chaye hamy

mcp har koi deta 
cloud b mcp 
vscode b mcp ki tara kam krta
cursor b mcp ki tara kam krta hai

set of tools hai jesko usekrny  k liya mcp client chaye

koi b currency cinvertor ana rhy hai ham
eska mtlb koi b bdna 100 dollar ko convert krdo kis b country k currency sy

mcp tool bnata Esko llm use krta jab zaroart hn ya protocol ko use krky bnata

vscode ma

library install
npm i \2modelcontextprotocol/sdk zod


currencyconvverted.js
import
McpServer @
stdioServerTransport llm or mcp k sth connect k liya
import {z} from 'zod'


const server=new McpServer({
name:"currencyconvertor mcp server,
version:"1.0.0"
})

server chlany k liya stdio chaye

async function startServer(params){
const transport=new stdioServerTransport();
await server.connect(transpirt)
}

startservr().catch(error)=>{
console.log("failded to sart mcp server|,error
process.exit(1)
}


server.tool(
"convertCurrency",
"Conver amount from one curenct to another" ll ko kab pata kgy ga chlana Esko
{
amount.a.number().describe("amount to convert")
from:z.strin.describe("base urent code eg USD",
to:z.string().describe(target current code eg INR")
)

Esko input parameter dy rhy ya outpu dy ga paramters


async (amount,from,to)())>{
try{
return {content:[
{
type"text",
text:converted currency is 100 INR'
} tool output dy g input lyga format batye ga
}}
catch(error){
return content[{type,text)}]


ya cirrencu convert ry ga llm ko call kry ga jab curreecny k bary ma pochy ham


ab cliud install kry ga desktop ma
cloud ma opr setting ma jaey ga develoeprs ma jaye ga
eidit config ma jaye ga es file ko vs code ma on kry ga

ab json file ma 
pwd krky terminal ma oath dyga wha

currency convertor:[
command:"node"
args:[path]
]







Build AI Agents + Workflows in 2025 

agr telegram ma msg kiya agent kasy drive sy meri idcard laye ga

multipe patform hai bana skty 
n8n best hai

n8n open source hai local ma run kr skty free trail dety ya start ma




ab hsieng er ma open kry ga\
hostinger open kry ga
vps choose kry ga 



Agent ‚Äúkya karna hai‚Äù decide karta hai
MCP ‚Äúkaise safely karna hai‚Äù handle karta hai




RAG Approach ‚Äî Theoretical Guide
RAG = Retrieval-Augmented Generation
Retrieval ‚Üí relevant data dhoondhna
Generation ‚Üí LLM se answer generate karna

Matlab:

‚ÄúLLM ko sirf internet ya training knowledge par rely na karne do,
balki apne custom data / documents / DB se relevant info do.‚Äù

Step 1: Data Collection

Pehle decide karo chatbot ka domain:
PDFs / Word docs / Excel sheets
Database (MySQL, PostgreSQL)
Web pages / APIs

Example: Company internal chatbot ‚Üí HR docs, Policy PDFs, FAQs

Step 2: Data Preprocessing
Text nikalna:
PDF ‚Üí text
Excel ‚Üí rows ‚Üí text
Clean karna:
Extra spaces, headers, formatting remove
Result: Clean chunks of text

Step 3: Text Chunks & Embeddings
Text ko chunks mein divide karo
Reason: LLM context limit hota hai
Example: 500 tokens per chunk
Har chunk ka embedding vector generate karo
Embeddings = numeric representation of text
Use: OpenAI embeddings / other embeddings model
Store embeddings in Vector Database
FAISS / Pinecone / Chroma / Weaviat

Step 4: Query Processing (User Question)
User chatbot se question poochta hai:
‚ÄúRefund policy kya hai?‚Äù
Question ko embedding mein convert karte hain
Same model jo text chunks ke liye use hua

Step 5: Retrieval

User question embedding ‚Üí vector DB mein search
Top-k relevant chunks nikaal lo
Example: top 3 chunks
Ye chunks hi chatbot ke liye context banenge

Step 6: LLM Generation
Prompt create karo:
Context: [Relevant Chunks]
User Question: [Your Question]
Answer in simple language.


LLM (GPT / Claude / Gemini) generate karega grounded answer

Output = Response to user

Step 7: Optional ‚Äî Memory / Conversation
Agar chatbot long conversation handle kare:
Previous interactions ko memory mein store karo
Next response ke liye context mein add karo

Step 8: Return Answer

Chatbot user ko response bhejta hai
Example:

User: ‚ÄúRefund policy kya hai?‚Äù
Bot: ‚ÄúAap 30 din ke andar product return kar sakte hain, full refund milega.‚Äù
